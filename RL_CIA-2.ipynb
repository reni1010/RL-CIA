{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set smaller grid size for testing\n",
    "GRID_SIZE = 10\n",
    "NUM_OBSTACLES = 10\n",
    "ACTION_SPACE = ['UP', 'DOWN', 'LEFT', 'RIGHT']\n",
    "gamma = 0.9\n",
    "theta = 1e-4\n",
    "max_iterations = 100\n",
    "\n",
    "# Initialize grid and place obstacles\n",
    "def create_grid():\n",
    "    grid = np.zeros((GRID_SIZE, GRID_SIZE))\n",
    "    for _ in range(NUM_OBSTACLES):\n",
    "        x, y = random.randint(0, GRID_SIZE - 1), random.randint(0, GRID_SIZE - 1)\n",
    "        grid[x, y] = 1\n",
    "    return grid\n",
    "\n",
    "# Ensure start and goal are open cells\n",
    "def initialize_start_goal(grid):\n",
    "    start, goal = (0, 0), (GRID_SIZE - 1, GRID_SIZE - 1)\n",
    "    while grid[start] == 1:\n",
    "        start = (random.randint(0, GRID_SIZE - 1), random.randint(0, GRID_SIZE - 1))\n",
    "    while grid[goal] == 1:\n",
    "        goal = (random.randint(0, GRID_SIZE - 1), random.randint(0, GRID_SIZE - 1))\n",
    "    return start, goal\n",
    "\n",
    "# Reward function\n",
    "def reward(state):\n",
    "    if state == goal:\n",
    "        return 10\n",
    "    elif grid[state] == 1:\n",
    "        return -10\n",
    "    else:\n",
    "        return -1\n",
    "\n",
    "# Transition model\n",
    "def transition(state, action):\n",
    "    x, y = state\n",
    "    if action == 'UP':\n",
    "        next_state = (max(x - 1, 0), y)\n",
    "    elif action == 'DOWN':\n",
    "        next_state = (min(x + 1, GRID_SIZE - 1), y)\n",
    "    elif action == 'LEFT':\n",
    "        next_state = (x, max(y - 1, 0))\n",
    "    elif action == 'RIGHT':\n",
    "        next_state = (x, min(y + 1, GRID_SIZE - 1))\n",
    "    return next_state if grid[next_state] == 0 else state\n",
    "\n",
    "# Value Iteration with debug output\n",
    "def value_iteration():\n",
    "    global V\n",
    "    for i in range(max_iterations):\n",
    "        delta = 0\n",
    "        for x in range(GRID_SIZE):\n",
    "            for y in range(GRID_SIZE):\n",
    "                state = (x, y)\n",
    "                if state == goal:\n",
    "                    continue\n",
    "                v = V[state]\n",
    "                new_value = max(reward(state) + gamma * V[transition(state, a)] for a in ACTION_SPACE)\n",
    "                V[state] = new_value\n",
    "                delta = max(delta, abs(v - new_value))\n",
    "        print(f\"Iteration {i}, max delta: {delta}\")\n",
    "        if delta < theta:\n",
    "            print(\"Converged!\")\n",
    "            break\n",
    "    else:\n",
    "        print(\"Reached maximum iterations without full convergence.\")\n",
    "\n",
    "# Extract policy with debug output\n",
    "def extract_policy():\n",
    "    policy = {}\n",
    "    for x in range(GRID_SIZE):\n",
    "        for y in range(GRID_SIZE):\n",
    "            state = (x, y)\n",
    "            if state == goal:\n",
    "                policy[state] = None\n",
    "            else:\n",
    "                best_action = max(ACTION_SPACE, key=lambda a: reward(state) + gamma * V[transition(state, a)])\n",
    "                policy[state] = best_action\n",
    "                print(f\"Policy for state {state}: {best_action}\")  # Debug output for each policy decision\n",
    "    return policy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start: (0, 0)\n",
      "Goal: (9, 9)\n",
      "Grid with obstacles:\n",
      " [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 1.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]]\n",
      "Iteration 0, max delta: 10.0\n",
      "Iteration 1, max delta: 0.9000000000000004\n",
      "Iteration 2, max delta: 0.8100000000000005\n",
      "Iteration 3, max delta: 0.7290000000000001\n",
      "Iteration 4, max delta: 0.6561000000000003\n",
      "Iteration 5, max delta: 0.5904900000000008\n",
      "Iteration 6, max delta: 0.531441\n",
      "Iteration 7, max delta: 0.47829690000000014\n",
      "Iteration 8, max delta: 0.43046720999999977\n",
      "Iteration 9, max delta: 0.38742048900000015\n",
      "Iteration 10, max delta: 0.3486784401000005\n",
      "Iteration 11, max delta: 0.3138105960900006\n",
      "Iteration 12, max delta: 0.28242953648099967\n",
      "Iteration 13, max delta: 0.25418658283290085\n",
      "Iteration 14, max delta: 0.22876792454961148\n",
      "Iteration 15, max delta: 0.20589113209465015\n",
      "Iteration 16, max delta: 0.18530201888518505\n",
      "Iteration 17, max delta: 0.16677181699666477\n",
      "Iteration 18, max delta: 0\n",
      "Converged!\n",
      "Policy for state (0, 0): RIGHT\n",
      "Policy for state (0, 1): DOWN\n",
      "Policy for state (0, 2): DOWN\n",
      "Policy for state (0, 3): DOWN\n",
      "Policy for state (0, 4): DOWN\n",
      "Policy for state (0, 5): DOWN\n",
      "Policy for state (0, 6): DOWN\n",
      "Policy for state (0, 7): DOWN\n",
      "Policy for state (0, 8): LEFT\n",
      "Policy for state (0, 9): DOWN\n",
      "Policy for state (1, 0): DOWN\n",
      "Policy for state (1, 1): DOWN\n",
      "Policy for state (1, 2): DOWN\n",
      "Policy for state (1, 3): DOWN\n",
      "Policy for state (1, 4): DOWN\n",
      "Policy for state (1, 5): RIGHT\n",
      "Policy for state (1, 6): DOWN\n",
      "Policy for state (1, 7): DOWN\n",
      "Policy for state (1, 8): DOWN\n",
      "Policy for state (1, 9): DOWN\n",
      "Policy for state (2, 0): DOWN\n",
      "Policy for state (2, 1): DOWN\n",
      "Policy for state (2, 2): DOWN\n",
      "Policy for state (2, 3): DOWN\n",
      "Policy for state (2, 4): DOWN\n",
      "Policy for state (2, 5): DOWN\n",
      "Policy for state (2, 6): DOWN\n",
      "Policy for state (2, 7): DOWN\n",
      "Policy for state (2, 8): DOWN\n",
      "Policy for state (2, 9): DOWN\n",
      "Policy for state (3, 0): DOWN\n",
      "Policy for state (3, 1): DOWN\n",
      "Policy for state (3, 2): DOWN\n",
      "Policy for state (3, 3): DOWN\n",
      "Policy for state (3, 4): DOWN\n",
      "Policy for state (3, 5): DOWN\n",
      "Policy for state (3, 6): DOWN\n",
      "Policy for state (3, 7): DOWN\n",
      "Policy for state (3, 8): LEFT\n",
      "Policy for state (3, 9): DOWN\n",
      "Policy for state (4, 0): DOWN\n",
      "Policy for state (4, 1): DOWN\n",
      "Policy for state (4, 2): DOWN\n",
      "Policy for state (4, 3): DOWN\n",
      "Policy for state (4, 4): DOWN\n",
      "Policy for state (4, 5): DOWN\n",
      "Policy for state (4, 6): DOWN\n",
      "Policy for state (4, 7): DOWN\n",
      "Policy for state (4, 8): DOWN\n",
      "Policy for state (4, 9): DOWN\n",
      "Policy for state (5, 0): DOWN\n",
      "Policy for state (5, 1): DOWN\n",
      "Policy for state (5, 2): DOWN\n",
      "Policy for state (5, 3): DOWN\n",
      "Policy for state (5, 4): DOWN\n",
      "Policy for state (5, 5): DOWN\n",
      "Policy for state (5, 6): RIGHT\n",
      "Policy for state (5, 7): DOWN\n",
      "Policy for state (5, 8): LEFT\n",
      "Policy for state (5, 9): DOWN\n",
      "Policy for state (6, 0): DOWN\n",
      "Policy for state (6, 1): DOWN\n",
      "Policy for state (6, 2): DOWN\n",
      "Policy for state (6, 3): DOWN\n",
      "Policy for state (6, 4): DOWN\n",
      "Policy for state (6, 5): DOWN\n",
      "Policy for state (6, 6): DOWN\n",
      "Policy for state (6, 7): DOWN\n",
      "Policy for state (6, 8): DOWN\n",
      "Policy for state (6, 9): DOWN\n",
      "Policy for state (7, 0): DOWN\n",
      "Policy for state (7, 1): DOWN\n",
      "Policy for state (7, 2): DOWN\n",
      "Policy for state (7, 3): DOWN\n",
      "Policy for state (7, 4): DOWN\n",
      "Policy for state (7, 5): DOWN\n",
      "Policy for state (7, 6): DOWN\n",
      "Policy for state (7, 7): RIGHT\n",
      "Policy for state (7, 8): DOWN\n",
      "Policy for state (7, 9): LEFT\n",
      "Policy for state (8, 0): RIGHT\n",
      "Policy for state (8, 1): RIGHT\n",
      "Policy for state (8, 2): RIGHT\n",
      "Policy for state (8, 3): RIGHT\n",
      "Policy for state (8, 4): DOWN\n",
      "Policy for state (8, 5): DOWN\n",
      "Policy for state (8, 6): DOWN\n",
      "Policy for state (8, 7): DOWN\n",
      "Policy for state (8, 8): DOWN\n",
      "Policy for state (8, 9): DOWN\n",
      "Policy for state (9, 0): UP\n",
      "Policy for state (9, 1): UP\n",
      "Policy for state (9, 2): UP\n",
      "Policy for state (9, 3): RIGHT\n",
      "Policy for state (9, 4): RIGHT\n",
      "Policy for state (9, 5): RIGHT\n",
      "Policy for state (9, 6): RIGHT\n",
      "Policy for state (9, 7): RIGHT\n",
      "Policy for state (9, 8): RIGHT\n",
      "Optimal policy extracted.\n",
      "Path taken: [(0, 0), (0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (8, 2), (8, 3), (8, 4), (9, 4), (9, 5), (9, 6), (9, 7), (9, 8), (9, 9)]\n",
      "Number of steps to goal: 18\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Initialize grid, start, and goal\n",
    "grid = create_grid()\n",
    "start, goal = initialize_start_goal(grid)\n",
    "\n",
    "# Verify start and goal positions\n",
    "print(\"Start:\", start)\n",
    "print(\"Goal:\", goal)\n",
    "print(\"Grid with obstacles:\\n\", grid)\n",
    "\n",
    "# Initialize the value function\n",
    "V = np.zeros((GRID_SIZE, GRID_SIZE))\n",
    "\n",
    "# Run Value Iteration\n",
    "value_iteration()\n",
    "\n",
    "# Extract and print the policy\n",
    "policy = extract_policy()\n",
    "print(\"Optimal policy extracted.\")\n",
    "\n",
    "# Evaluate and display path taken\n",
    "def evaluate_policy(start, policy):\n",
    "    state = start\n",
    "    steps = 0\n",
    "    path = [state]\n",
    "    while state != goal and steps < GRID_SIZE * 2:  # Avoid infinite loop\n",
    "        action = policy.get(state)\n",
    "        if action is None:\n",
    "            break\n",
    "        next_state = transition(state, action)\n",
    "        if next_state == state:\n",
    "            print(f\"Agent stuck at state {state} with action {action}\")\n",
    "            break\n",
    "        state = next_state\n",
    "        path.append(state)\n",
    "        steps += 1\n",
    "    return path, steps\n",
    "\n",
    "path, steps = evaluate_policy(start, policy)\n",
    "print(\"Path taken:\", path)\n",
    "print(\"Number of steps to goal:\", steps)\n",
    "\n",
    "# Plot the path\n",
    "def plot_path(grid, path, start, goal):\n",
    "    plt.imshow(grid, cmap='gray_r')\n",
    "    for (y, x) in path:\n",
    "        plt.scatter(x, y, c='blue', marker='.', s=10)\n",
    "    plt.scatter(start[1], start[0], c='green', marker='o', label=\"Start\")\n",
    "    plt.scatter(goal[1], goal[0], c='red', marker='x', label=\"Goal\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "plot_path(grid, path, start, goal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
